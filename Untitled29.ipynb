{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled29.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabumjung/Tensorflow/blob/master/Untitled29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wLc9gs1Y29ih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5ca28fe6-c2d1-417b-dc1a-3f55fc215d1e"
      },
      "cell_type": "code",
      "source": [
        "##################################### Parameter\n",
        "# 1. 라이브러리 가져오기\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist=input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\n",
        "# 2. 하이퍼파라미터를 설정\n",
        "total_epoch=100\n",
        "batch_size=100\n",
        "learning_rate=0.0002\n",
        "n_hidden=256\n",
        "n_input=28*28\n",
        "# 생성자의 입력값으로 사용할 노이즈의 크기\n",
        "n_noise=128\n",
        "\n",
        "# 3. 플레이스홀더 설정(입력값, 노이즈값)\n",
        "X=tf.placeholder(tf.float32, [None, n_input])\n",
        "Z=tf.placeholder(tf.float32, [None, n_noise])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "69ds1Jx-66Pr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###################################### Model\n",
        "#4. 생성자 신경망에 사용할 변수를 설정\n",
        "# 은닉층으로 출력하기 위한 변수 [128, 256] + [1, 256]\n",
        "G_W1=tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
        "G_b1=tf.Variable(tf.zeros([n_hidden]))\n",
        "# 출력층에 사용할 변수  [256, 784] + [1, 784]  \n",
        "G_W2=tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
        "G_b2=tf.Variable(tf.zeros([n_input]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-GCjqYF2_r5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "8214ae5e-c755-4a77-9075-9fb5e0bbaf67"
      },
      "cell_type": "code",
      "source": [
        "print(\"%s \\n %s \\n %s \\n %s\" % (G_W1, G_b1, G_W2, G_b2))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_20:0' shape=(128, 256) dtype=float32_ref> \n",
            " <tf.Variable 'Variable_21:0' shape=(256,) dtype=float32_ref> \n",
            " <tf.Variable 'Variable_22:0' shape=(256, 784) dtype=float32_ref> \n",
            " <tf.Variable 'Variable_23:0' shape=(784,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "shSqTLAw3vsZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#5. 구분자 신경망에 사용할 변수를 설정\n",
        "# 은닉층으로 출력하기 위한 변수\n",
        "D_W1=tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
        "D_b1=tf.Variable(tf.zeros([n_hidden]))\n",
        "# 출력층에 사용할 변수\n",
        "D_W2=tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
        "D_b2=tf.Variable(tf.zeros([1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPn3DdYX4xxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "89134df6-d1a1-406e-9784-da22614026ea"
      },
      "cell_type": "code",
      "source": [
        "print(\"%s \\n %s \\n %s \\n %s\" % (G_W1, G_b1, G_W2, G_b2))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_20:0' shape=(128, 256) dtype=float32_ref> \n",
            " <tf.Variable 'Variable_21:0' shape=(256,) dtype=float32_ref> \n",
            " <tf.Variable 'Variable_22:0' shape=(256, 784) dtype=float32_ref> \n",
            " <tf.Variable 'Variable_23:0' shape=(784,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Icfermll4zGf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(noise_z):\n",
        "  hidden=tf.nn.relu(tf.matmul(noise_z, G_W1)+G_b1)\n",
        "  output=tf.nn.sigmoid(tf.matmul(hidden, G_W2)+G_b2)\n",
        "  return(output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-T1WUCn5E5_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator(inputs):\n",
        "\thidden=tf.nn.relu(tf.matmul(inputs, D_W1)+D_b1)\n",
        "\toutput=tf.nn.sigmoid(tf.matmul(hidden, D_W2)+D_b2)\n",
        "\treturn output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CprGXH3S5Z9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_noise(batch_size, n_noise):\n",
        "\treturn np.random.normal(size=(batch_size, n_noise))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "icF0jwcE5hAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4780ee9b-0735-408d-89dd-02e33ed9def2"
      },
      "cell_type": "code",
      "source": [
        "A1=tf.nn.relu(tf.matmul(Z, G_W1)+G_b1)\n",
        "A2=tf.nn.sigmoid(tf.matmul(A1, G_W2)+G_b2)\n",
        "# D_gene=discriminator(G)\n",
        "# D_real+discriminator(X)\n",
        "print(\"%s   %s   %s   %s\" % (A1.shape, Z.shape, G_W1.shape, G_b1.shape ))\n",
        "print(\"%s   %s   %s   %s\" % (A2.shape, A1.shape, G_W2.shape, G_b2.shape))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 256)   (?, 128)   (128, 256)   (256,)\n",
            "(?, 784)   (?, 256)   (256, 784)   (784,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IepDcSq-55Rw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "G=generator(Z)\n",
        "D_gene=discriminator(G)\n",
        "D_real=discriminator(X)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "liZZdbd66vOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ff72bd7c-cc92-40e6-ca2f-19e2b5d9f9f8"
      },
      "cell_type": "code",
      "source": [
        "print \"%s \\n %s \\n %s\" % (G, D_gene, D_real)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Sigmoid_8:0\", shape=(?, 784), dtype=float32) \n",
            " Tensor(\"Sigmoid_9:0\", shape=(?, 1), dtype=float32) \n",
            " Tensor(\"Sigmoid_10:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xn7YT8Rs83OJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_D=tf.reduce_mean(tf.log(D_real)+tf.log(1-D_gene))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1V1zW2SaBZt4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_G=tf.reduce_mean(tf.log(D_gene))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9oZqwWJ7BeeY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "D_var_list=[D_W1, D_b1, D_W2, D_b2]\n",
        "G_var_list=[G_W1, G_b1, G_W2, G_b2]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xhgTFKGgBg1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_D=tf.train.AdamOptimizer(learning_rate).minimize(-loss_D, var_list=D_var_list)\n",
        "train_G=tf.train.AdamOptimizer(learning_rate).minimize(-loss_G, var_list=G_var_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3FEYMECIBj75",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess=tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "total_batch=int(mnist.train.num_examples/batch_size)\n",
        "loss_val_D, loss_val_G=0,0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3L0Ewz_cBnyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f83df722-5bc5-4508-bed0-063bba73a42f"
      },
      "cell_type": "code",
      "source": [
        "print(total_batch,mnist.train.num_examples,batch_size)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(550, 55000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EhOp1HzBBq1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1817
        },
        "outputId": "75382dc1-b3ec-4c44-9746-28b54504f1c5"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(total_epoch):\n",
        "\tfor i in range(total_batch):\n",
        "\t\tbatch_xs, batch_ys=mnist.train.next_batch(batch_size)\n",
        "\t\tnoise=get_noise(batch_size, n_noise)\n",
        "\t\t_, loss_val_D=sess.run([train_D, loss_D],feed_dict={X:batch_xs, Z:noise})\n",
        "\t\t_, loss_val_G=sess.run([train_G, loss_G],feed_dict={Z:noise})\n",
        "\tprint('Epoch:', '%04d' % epoch,\n",
        "        'D loss: {:.4}'.format(loss_val_D),\n",
        "        'G loss: {:.4}'.format(loss_val_G))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Epoch:', '0000', 'D loss: -0.4596', 'G loss: -2.059')\n",
            "('Epoch:', '0001', 'D loss: -0.4934', 'G loss: -2.082')\n",
            "('Epoch:', '0002', 'D loss: -0.3108', 'G loss: -2.342')\n",
            "('Epoch:', '0003', 'D loss: -0.3369', 'G loss: -1.856')\n",
            "('Epoch:', '0004', 'D loss: -0.4596', 'G loss: -2.047')\n",
            "('Epoch:', '0005', 'D loss: -0.2033', 'G loss: -3.325')\n",
            "('Epoch:', '0006', 'D loss: -0.2296', 'G loss: -2.989')\n",
            "('Epoch:', '0007', 'D loss: -0.2387', 'G loss: -3.051')\n",
            "('Epoch:', '0008', 'D loss: -0.3371', 'G loss: -2.674')\n",
            "('Epoch:', '0009', 'D loss: -0.2454', 'G loss: -2.644')\n",
            "('Epoch:', '0010', 'D loss: -0.2825', 'G loss: -2.971')\n",
            "('Epoch:', '0011', 'D loss: -0.3381', 'G loss: -2.662')\n",
            "('Epoch:', '0012', 'D loss: -0.2844', 'G loss: -2.545')\n",
            "('Epoch:', '0013', 'D loss: -0.2938', 'G loss: -3.075')\n",
            "('Epoch:', '0014', 'D loss: -0.2507', 'G loss: -2.909')\n",
            "('Epoch:', '0015', 'D loss: -0.2893', 'G loss: -2.698')\n",
            "('Epoch:', '0016', 'D loss: -0.3478', 'G loss: -2.628')\n",
            "('Epoch:', '0017', 'D loss: -0.3768', 'G loss: -2.67')\n",
            "('Epoch:', '0018', 'D loss: -0.333', 'G loss: -3.061')\n",
            "('Epoch:', '0019', 'D loss: -0.4643', 'G loss: -2.242')\n",
            "('Epoch:', '0020', 'D loss: -0.3482', 'G loss: -2.615')\n",
            "('Epoch:', '0021', 'D loss: -0.5722', 'G loss: -2.253')\n",
            "('Epoch:', '0022', 'D loss: -0.3637', 'G loss: -2.449')\n",
            "('Epoch:', '0023', 'D loss: -0.4843', 'G loss: -2.703')\n",
            "('Epoch:', '0024', 'D loss: -0.362', 'G loss: -2.885')\n",
            "('Epoch:', '0025', 'D loss: -0.5124', 'G loss: -2.808')\n",
            "('Epoch:', '0026', 'D loss: -0.4484', 'G loss: -2.706')\n",
            "('Epoch:', '0027', 'D loss: -0.2715', 'G loss: -3.243')\n",
            "('Epoch:', '0028', 'D loss: -0.486', 'G loss: -2.918')\n",
            "('Epoch:', '0029', 'D loss: -0.3121', 'G loss: -2.624')\n",
            "('Epoch:', '0030', 'D loss: -0.395', 'G loss: -2.985')\n",
            "('Epoch:', '0031', 'D loss: -0.4147', 'G loss: -2.774')\n",
            "('Epoch:', '0032', 'D loss: -0.4562', 'G loss: -2.524')\n",
            "('Epoch:', '0033', 'D loss: -0.3916', 'G loss: -2.493')\n",
            "('Epoch:', '0034', 'D loss: -0.289', 'G loss: -2.881')\n",
            "('Epoch:', '0035', 'D loss: -0.3165', 'G loss: -3.066')\n",
            "('Epoch:', '0036', 'D loss: -0.3985', 'G loss: -3.086')\n",
            "('Epoch:', '0037', 'D loss: -0.6246', 'G loss: -2.522')\n",
            "('Epoch:', '0038', 'D loss: -0.5416', 'G loss: -2.715')\n",
            "('Epoch:', '0039', 'D loss: -0.5238', 'G loss: -2.232')\n",
            "('Epoch:', '0040', 'D loss: -0.5515', 'G loss: -2.063')\n",
            "('Epoch:', '0041', 'D loss: -0.5168', 'G loss: -2.553')\n",
            "('Epoch:', '0042', 'D loss: -0.6019', 'G loss: -2.37')\n",
            "('Epoch:', '0043', 'D loss: -0.6182', 'G loss: -2.472')\n",
            "('Epoch:', '0044', 'D loss: -0.4273', 'G loss: -2.321')\n",
            "('Epoch:', '0045', 'D loss: -0.7086', 'G loss: -2.212')\n",
            "('Epoch:', '0046', 'D loss: -0.5978', 'G loss: -2.247')\n",
            "('Epoch:', '0047', 'D loss: -0.6806', 'G loss: -1.939')\n",
            "('Epoch:', '0048', 'D loss: -0.5761', 'G loss: -2.233')\n",
            "('Epoch:', '0049', 'D loss: -0.5868', 'G loss: -2.489')\n",
            "('Epoch:', '0050', 'D loss: -0.8063', 'G loss: -2.021')\n",
            "('Epoch:', '0051', 'D loss: -0.725', 'G loss: -2.069')\n",
            "('Epoch:', '0052', 'D loss: -0.6544', 'G loss: -1.993')\n",
            "('Epoch:', '0053', 'D loss: -0.7013', 'G loss: -2.194')\n",
            "('Epoch:', '0054', 'D loss: -0.6316', 'G loss: -2.056')\n",
            "('Epoch:', '0055', 'D loss: -0.6574', 'G loss: -2.176')\n",
            "('Epoch:', '0056', 'D loss: -0.8058', 'G loss: -1.893')\n",
            "('Epoch:', '0057', 'D loss: -0.7271', 'G loss: -1.991')\n",
            "('Epoch:', '0058', 'D loss: -0.6256', 'G loss: -2.225')\n",
            "('Epoch:', '0059', 'D loss: -0.5689', 'G loss: -2.062')\n",
            "('Epoch:', '0060', 'D loss: -0.6081', 'G loss: -1.879')\n",
            "('Epoch:', '0061', 'D loss: -0.8192', 'G loss: -1.871')\n",
            "('Epoch:', '0062', 'D loss: -0.6352', 'G loss: -2.342')\n",
            "('Epoch:', '0063', 'D loss: -0.6363', 'G loss: -2.14')\n",
            "('Epoch:', '0064', 'D loss: -0.8128', 'G loss: -1.889')\n",
            "('Epoch:', '0065', 'D loss: -0.6135', 'G loss: -2.191')\n",
            "('Epoch:', '0066', 'D loss: -0.7104', 'G loss: -1.953')\n",
            "('Epoch:', '0067', 'D loss: -0.6686', 'G loss: -1.959')\n",
            "('Epoch:', '0068', 'D loss: -0.7782', 'G loss: -1.86')\n",
            "('Epoch:', '0069', 'D loss: -0.7273', 'G loss: -1.917')\n",
            "('Epoch:', '0070', 'D loss: -0.6089', 'G loss: -2.147')\n",
            "('Epoch:', '0071', 'D loss: -0.6538', 'G loss: -1.985')\n",
            "('Epoch:', '0072', 'D loss: -0.8119', 'G loss: -1.972')\n",
            "('Epoch:', '0073', 'D loss: -0.646', 'G loss: -2.049')\n",
            "('Epoch:', '0074', 'D loss: -0.7515', 'G loss: -1.916')\n",
            "('Epoch:', '0075', 'D loss: -0.7323', 'G loss: -1.95')\n",
            "('Epoch:', '0076', 'D loss: -0.7235', 'G loss: -2.157')\n",
            "('Epoch:', '0077', 'D loss: -0.5717', 'G loss: -2.188')\n",
            "('Epoch:', '0078', 'D loss: -0.7527', 'G loss: -2.011')\n",
            "('Epoch:', '0079', 'D loss: -0.6832', 'G loss: -1.852')\n",
            "('Epoch:', '0080', 'D loss: -0.7528', 'G loss: -2.203')\n",
            "('Epoch:', '0081', 'D loss: -0.6667', 'G loss: -1.977')\n",
            "('Epoch:', '0082', 'D loss: -0.8341', 'G loss: -1.86')\n",
            "('Epoch:', '0083', 'D loss: -0.7999', 'G loss: -1.808')\n",
            "('Epoch:', '0084', 'D loss: -0.7635', 'G loss: -1.805')\n",
            "('Epoch:', '0085', 'D loss: -0.619', 'G loss: -2.195')\n",
            "('Epoch:', '0086', 'D loss: -0.6347', 'G loss: -1.759')\n",
            "('Epoch:', '0087', 'D loss: -0.7125', 'G loss: -1.792')\n",
            "('Epoch:', '0088', 'D loss: -0.6953', 'G loss: -2.084')\n",
            "('Epoch:', '0089', 'D loss: -0.8025', 'G loss: -2.223')\n",
            "('Epoch:', '0090', 'D loss: -0.5637', 'G loss: -2.152')\n",
            "('Epoch:', '0091', 'D loss: -0.7409', 'G loss: -1.89')\n",
            "('Epoch:', '0092', 'D loss: -0.6369', 'G loss: -2.39')\n",
            "('Epoch:', '0093', 'D loss: -0.5667', 'G loss: -2.024')\n",
            "('Epoch:', '0094', 'D loss: -0.7067', 'G loss: -1.999')\n",
            "('Epoch:', '0095', 'D loss: -0.7631', 'G loss: -1.86')\n",
            "('Epoch:', '0096', 'D loss: -0.5569', 'G loss: -2.321')\n",
            "('Epoch:', '0097', 'D loss: -0.8311', 'G loss: -2.045')\n",
            "('Epoch:', '0098', 'D loss: -0.5682', 'G loss: -2.192')\n",
            "('Epoch:', '0099', 'D loss: -0.6808', 'G loss: -1.902')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YqH9dfFABxxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d4c8787f-2500-428c-98d2-faeeb8603459"
      },
      "cell_type": "code",
      "source": [
        "if epoch==0 or (epoch+1) %10==0:\n",
        "\tsample_size=10\n",
        "\tnoise=get_noise(sample_size, n_noise)\n",
        "\tsamples=sess.run(G, feed_dict={Y:mnist.test.labels[:sample_size], Z:noise})\n",
        "\n",
        "  fig, ax=plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
        "\n",
        "  for i in range(sample_size):\n",
        "    ax[i].set_axis_off()\n",
        "    ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
        "\n",
        "plt.savefig(‘samples/{}.png’.format(str(epoch).zfill(3)),\n",
        "\t\t\tbbox_inches=’tight’)\n",
        "plt.close(fig)\n",
        "print(‘최적화 완료’)\n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-98-1695b59f2002>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    fig, ax=plt.subplots(1, sample_size, figsize=(sample_size, 1))\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AYe8YJe2DmvI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}